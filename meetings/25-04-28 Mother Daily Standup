Mother Daily Standup - April 28
VIEW RECORDING - 70 mins (No highlights): https://fathom.video/share/FsoxPoPUzZAusRjXkFYEvzcGybHyFZDS

---

0:00 - Alex Lumley
  Yeah, I think so.

0:02 - Jonathan Miller (miller.d.jonathan@gmail.com)
  wasn't like a cyber attack, which everyone says, because they would knock out like two countries, and like, I don't think that they share a power grid, so it's like very odd that it happens, and then parts of France were affected, and yeah, super wild.

0:18 - James Young (Collabü§ùLand)
  It's a dry run. Yeah, I guess so. All right, we'll give it a minute for Tosh and 08 to come online, and I'll give my updates, and then I have another other update.  I was talking to Alex about this, but before we begin, is there anything, Alex or Coach Jay, you want to put on the agenda?  No.

0:48 - Jonathan Miller (miller.d.jonathan@gmail.com)
  I'm at this morning with Tash and 08 and I think we're just curious to see where the build is at, and then, like, how that's going, and then based on that, I mean, like, we're kind of like‚Ä¶ Yeah.  As as that's done and we're feeling confident with it, then we're going to immediately start some promotions, and then two to three days later, we'll run our first activation in Discord.  So the timeline is kind of like, as soon as the product is ready, then we're not going to start advertising it before it's ready to go.  Yeah. And otherwise, to discuss, just an update for a really quick thing for Alex, just about grants. Like, 08 is going to look into them.  Specifically, the base one is probably the most likely candidate, but like, grants are hard right now. Grants are buckled down, so, for us.  And then on the agenda, I think that's it. And I can go over some of the comms that we've put out for the thing, but we could do that today.  can do that tomorrow. I mean, I'm just waiting for Tosh to... I don't know if she could come on, her power is also out, and I don't know if Portugal can come Oh, I see.

2:09 - James Young (Collabü§ùLand)
  I see. I see. Okay, well, let's just dive into it then. So, one thing before we talk about which will be the meat of this conversation being built, that I found out this morning that Gaia is doing an open MCP server.  I posted it in Mother and the period chat just to kind of understand. I don't know if it's going to be folded into Mother or what Matt's plans are, but it has payments and multi-agent MCP kind of things that we've been talking about for months, but I just want to disclose all of that info because this is the first I'm hearing about it.  And Matt hasn't signaled to me or told me about if this is competitive to mother or if this is complementary or what the positioning is for that, because we could definitely leverage some of that, so it's a bit curious to me.  So I just wanted to flash. going that for the core team here. And. Yeah, and what he's thinking about it.  So just wanted to note that and... It's been a little bit difficult for me to get a hold of Matt from like a meeting perspective, he seems super busy.  So usually the weekends are the time when I have overflow and I usually chat with Matt over the weekends, but we'll start mapping out now transitioning into where the build is at.  So what I've built out so far, first I wanted to take it into steps. So this is going to be the orchestra, just to release it, is the orchestra agent is going to have these subfolders where there are going to be multiple agents eventually that will, and these are basically placeholders.  So agent, a contract, a smart contract agent, a formatter agent, an account kit agent, and a quiz agent. So this is all going to be just to get it out, just placeholders for 5A agent, and the code though is all going to be split out to the contract agent, discord formatter agent, account kit agent, quiz agent.  But they're all placeholders now. And eventually I'm assuming that these will all be using was a discord template environment so that anyone can easily spin up and boot a discord agent that will be, you know, And to be on the reference implementation so that we can have a better fast track.  So I spent it, and I don't know, maybe I didn't have these best practices either at the beginning, where you just, it's like, I can imagine thousands of lines of LLM.txt where you're giving the AI agent just let's design this.  So that's the kind of the guardrail on the left side. And I would imagine like kind of guardrail on the right side, where the code is actually what you're trying to get out eventually.  But if you really design and just spend a lot of time, which I did on agents and it gave me ideas and how to compose everything, that's done.  Now, I've also did test cases. So that's the right side of the guardrail. So if the code starts to hallucinate, or if the agent starts to hallucinate with a code, and it doesn't pass you the tests, then, so you don't have to worry about hallucinations.  So this is the kind of. Strength guardrails that I'm forming as best practices as I was doing this this weekend and just for everyone's edification.  And then you tell it to start coding. So I had it start coding. And what I've done is I've come up with the basic Discord formatter and I have the orchestrator and I have a smart contract.  As I was designing this, one of the things that I've come out with, and this is not in the Notion spec, is that every single interaction is going to be on chain.  So I created a quiz factory contrast and just because I know that Tosh had this formula, what I actually did, and this is how the contract is set up, because it was, you know, when I was designing it, this was the most straightforward way I can communicate with the LLM.  Or the IDE agent was 75% of correct answers have a pot, 25% of the incorrect answers have a pot.  And you pull from that. And another constraint is that what gets divvied out when it comes to the winners and losers, the losers can never make more than a winner makes, you know, because there's some math there where, like, if you only have one or two correct answers, but many or a lot of correct answers and just a few incorrect answers, the pro rata share could get off balance.  So it can incentivize you to, like, make a wrong answer. So I had that. And then also, there's, like, there's a bunch of detail that I kind of went down a rabbit hole with the QuizSmart contract in terms of reentrancy.  And I actually had the ID agent kind of be the auditor. So it audited the code, and there was all these attack vectors, and I spent an enormous amount of time making sure that the contract was kind of bulletproof, and what I had to net out was I had to also put out like a refund and emergency stop so that like if there's something wrong with the quiz or if it's a high state quiz, that the quiz creator could like pull the plug and stop it, but then also has to give a reason as why it's stopping and why it's starting.  So everything is like fully transparent on chain, and that led me to, and in the design phase, I need a separate contract agent that just like writes and audits and everything smart contract.  So there's a lot of hidden work that like not going into this, I think when we talked on Friday was just kind of high level and didn't give a spotlight into the technical nuance, and so I have that.  I spoke with Geeta about that this morning. And he's going to help, like, on the Account Kit side. But that's kind of where I'm at right now, and that's what I spent the weekend vibing with, which was fun, actually.  It was really fun, actually, because it was just, you know, kind of talking. It's like English is now the programming language.  It's really funny. Anyway, I can go on forever. Alex?

11:28 - Alex Lumley
  Alex, I'll have a other questions about, like, what you actually created and stuff, but I was talking about, as a side note about the Viacoding designing, I was talking to my cousin about it, and he, like, built a couple of apps for himself.  He hasn't programmed in, like, 12 years, and I realized, like, I was like, oh, you can do this to test out the business and do all these things, and then I realized he's actually feeling more like an artist.  And it was, like, for the first time in this life, he was this is the most creative thing I've done in years.

11:54 - James Young (Collabü§ùLand)
  I feel like an artist.

11:55 - Alex Lumley
  This isn't about making a business. It's not, like, just building something for myself, which I thought was super interesting.  you. It puts you into a different vector or a different space than you would normally. And you were able to do the architecture and do the unit tests and then just let the junior engineer do all the work.  Right. Yeah.

12:15 - James Young (Collabü§ùLand)
  It is what's really fascinating and coming from a developer background, I was never into marketing, but because I've been doing collab line for so many years, there's all this, like, anecdotal information that I know that, like, are playbooks that make communities work.  And I've actually have a thread with ChatGPT about this, and I'm vibe marketing. So it's marketing code. All of this is now can be done by one person instead of having teams, huge teams do it.  And what I've learned, to your point, Alex, is code. It is content now because, like, it's like if I'm an artist, I make content, whether I'm doing a video, which I can do with AI, audio, you know, animations and all of this.  And so this is what AI kind of unlocks. And what I've seen with all of the major frontier models is they're really focusing on code generation.  But it's going to go into marketing. It's going to go into, like, you see it in images, songs, all this.  But the code, because engineers are the ones that are making the LLMs, the code is closest to them, and it is, like, the code that is supposed to be written is deterministic.  There's no real room for interpretation. It either works as a bug or it doesn't work. So that's kind of where it's starting.  And I think when I was reading a few AI papers, DeepSeq has come up with alpha proof. Alpha proof is where they're moving toward.  and of the of And also, I've got some insight from people at Google that just kind of coming from multiple sources, Google is spending 80% of their time on AI on multi-agents.  So multi-agents are the big next research thing, and alpha proof, what DeepSeek has written on the paper, if you just Google DeepSeek alpha proof, you'll see that you don't need a large model.  You need small models, and so initially, the way that AI industry, from my perspective, has taken off is like, you have pre-training.  You have all these models, you pre-train, it takes a lot of CPU or GPU, and you have these weights and all of this, closed source, open source.  And then, now, we're in this like, kind of fine-tuning. So there's RAG to add more context to these large data sets.  What Alphaproof with DeepSeq is saying, you don't need a lot of pre-training and you don't need a lot of RAG.  The third phase of AI agents with Alphaproof is you have to deploy your agent as quickly as you can, and it interacts with the environment.  It's environmental AI. And then that's how it learns. gets bespoke knowledge, and that loops back. And so it's really interesting because what we're doing at Mother with Verifiable Decentralized AI all fits into what Google is doing with multi-agents and what Alphaproof is going toward, because when Alphaproof is interacting, what DeepSeq and Anthropic, Anthropic is also on this bandwagon, they need to verify the inference through this interactivity, because you can't trust that information.  Because in this environment, it could be hostile. So all the inference needs to be verified. So this all leads.  This decentralized AI and what we're doing, Mother. So it got me really hyped, just kind of what we're doing is where the AI industry as a whole is going.  And it makes logical sense to me. I have to check my confirmation bias and not get overhyped on it.  But this is really interesting. So as we deploy these agents in the context of communities, it could be kind of dumb at the beginning.  And it learns through reading the chat messages, understanding what agents want. And then the agent can deploy other, can create and birth other agents in this multi-agent world that's bespoke to the context of that community.  So we can start with vibe coding. We can start with or vibe marketing for these communities, but these communities are going to have their own bespoke marketing models.  And the agent needs to be deployed in the context of this environment so that it can learn and understand the vibe of the community in general.  To then know how to refine the playbook specifically for that community. And this is where it's like you have this synthetic-led organizations where it's human agents in an environment that learn and adapt to one another.  And this is, I think, where this phase will be unlocked, but this is where AI, I think, as I was reading, researching, and biodecoding.  Because what I would do is I would have, like, a paper or two on the left side, I had my, you know, windsurf on the right, it has to think, and it's doing all this stuff, and instead of waiting for five minutes and then just getting on my phone and scrolling, I'm reading these papers, and it's just like, oh, I'm making these connections as I'm doing it.  And so it's really fascinating. And again, I could talk about this for hours, but this is where I'm at.

17:52 - Jonathan Miller (miller.d.jonathan@gmail.com)
  Could I share, now that you got to go on a tangent, could I go on a, I swear, three-minute tangent on the things that I saw this weekend?  Really quick, so the first one is I've also been Vivecoding, and it just so happened that Lovable did an upgrade to their system, like I had given up on this project, I got like 80% there, and like I was just having such a hard time, and right when I gave up, like the next day, Lovable upgraded their system, and basically what they did is they added like a reasoning layer, so what I can do is I can chat to the chat box, and then it comes up with a plan with me, and then I just say implement the plan, and a degree, like it's so much better than what it was before, I solved like a bunch of problems really quickly, and now I'm very confident that in the next week, I'll like be able to like finally finish this project, so the Vivecoding is getting like wild good, and I'm not technical, like at all, so it's really amazing that that happened.  The second thing I think is super interesting that you shared is is So You kind of mentioned that you're by marketing and by coding and all this kind of stuff.  I literally listened to this talk about how what these large corporations are seeing is that we're going to see what we've seen over the industrial era to the post-industrial era is this specialization, this hyper-specialization.  You go to these giant corporations and there are people that are super specialized in these very specific things. But what's going to end up happening is that AI is going to replace those people and we're going to see the rise of the generalist who can actually manage teams of AI agents because they don't need to know that information.  They can get those AIs to create that information and then they can use that information to make decisions about how to move forward and stuff like that.  So I thought that was super cool as well. And then the last one was, yeah, I just think that this like move toward agents is.  Like, this one consultancy that I, like, follow pretty closely, they were actually going to launch a whole course, like, how to use chatbots and stuff like that.  And they, like, completely scrapped it because they're like, this is a waste of time in 6 to 12 months.  Like, this is going to be useless. And it's literally all about how to manage and orchestrate teams of agents.  So it's great that we're here and we're looking at this already because I think this is kind of, like, the benefit of what we're doing.  And it's also the challenge is that we're, like, a little bit ahead of the curve. And it's about, like, really timing that market perfectly.  So anyway, that was my end tangent. No, that's great.

20:37 - James Young (Collabü§ùLand)
  I mean, I think that this is where it's interesting because if I knew about MCP and A to A and AITP, when we started on the starter kit, it would have looked very different, but it didn't even exist.  And so what is going to exist in the next two weeks, one month? But at the same time, you can't just wait and sit back, right?  And so this is the challenge of just... We're adjusting every single time, and that's why right now I'm balancing just go to market and getting this orchestrator agent with the whole agent, but carving out placeholders for these other agents as well, anticipating that like, you know, there's going to be this maturity and we know that the multi-agent is going to work.  So instead of trying to build something that may not happen by being three to six months out, I mean, even like the CPO of OpenAI saying they don't have a one-year roadmap.  They maybe have a six-year roadmap, they have just a three-month roadmap. So it's a pretty, we're in this kind of renaissance era right now, and who knows how long this window will stay open, but this is the time where you have to be in the midst of it so that you understand kind of, like, you can be told this stuff, but unless...  So, yeah, that's why I'm also sharing kind of broader context and what I'm doing because sharing this broader context may or may not result in future conversations or tangents that may become the main thread.  So, it's like keeping an eye on what's happening kind of at the same time that you're doing it and having these wider conversations.  We don't have to ever talk about the details of things. Like, we'll just let the agent kind of figure it out.  I mean, I was able to get a lot of good insight and questions as I was designing because I assumed that, like, there was some nuance that I was, like, glossing over.  And then when the agent was parroting back the design, I was like, no, no, no, that's not right. And so, I went through this, like, kind of overindulgence of the design phase.  So... That it's like teaching someone that is, like, super autistic, that has no, that can just code, but has no other understanding.  That's like, I've seen coders like that. So I kind of treated the IDE agent like that. And so just, you know, instead of an hour conversation about this is why we're doing something, I just was able to chat and get back and forth responses from these elements.  And I think that one of the important things is that these LLMs know JavaScript, know, like, Ruby on Rails, know Python really well, but these other bespoke languages, like Rust, or, you know, these new languages, it's hard.  And even the LLM, even using Sonnet 3.7, it doesn't know about MCP well, yet, because it just came out.  So you've got to wait a little bit for the models to update. And the more code pool there is, like C++ code, you know, round.  For, I don't know, you know, decades, like generations since the 60s. And so it's easier and you have to kind of choose your weapon that way as well.  And so these are the things that going into Vibe Coding, people don't know. And I don't know what that context is from like a marketing perspective.  What are the tried and true marketing strategies that are kind of like Seth Godin, right? When he talks about marketing and selling, like it's values and principles that have a lot of literature behind it that the LLM can then just capture and then use.  Because if it doesn't have a wide knowledge set to scrape from, it's not going to really know. And so part of being a Vibe Coder or Vibe Marketer is understanding the wider context of what's available as well.  And then this is where Grok comes in because Grok knows the timeline so well and has a... So you have to know which tools to use at which moment, and this is a kind of learning that you only get when you're actually doing it.  So, you know, these are the tricks or tips which have a shelf life of like weeks or months, if that, and then it kind of moves on.  So it's like if you don't know what is possible and then what becomes obsolete, when you try and get to there or what in the market moves on, you're not going to have, as a human, it's like you have to, as a human, have that broader context.  You're not going to be able to wield the AI agents adequately. And I think that's not what a lot of people are focused on.  They're just trying to get a replacement for that like junior engineer. So anyway, this is a broader context, broader learnings that you can't get unless you're actually in the arena.  So, yeah, I have to get off my sofa.

26:02 - Alex Lumley
  I have some more we can talk about for that, but I guess we're running out of time. Is there any other immediate next steps on this?

26:11 - James Young (Collabü§ùLand)
  I think that what I would like to do is see if we can start creating a repo of kind of even putting the community plan and updating it, and then the LLM can learn about that as well as have access to the code, and there may be some insights.  There's context that we have, right, that are gaps because we're communicating and have different points of view that the LLM can, like, put together, and what I would recommend is, like, just designing a community plan, a marketing plan, not the specific steps, but what you want, who do you want to reference, like, be this marketer, be this community, see their on-chain growth, see their on-chain transactions, put it all, like, in an LLM.  LLMs.txt file, and every time I... What I do is I say, in this session, because it's in my local working memory, in my Windsurf account, dump it all into a notes.txt file or lms.txt file so that it can be picked up by another IDE agent.  That is the metadata that I think is going to be super valuable for us, and we will have an incredible edge over, because then if people leave or things happen or someone's not in a meeting or whatever it is, they can catch up via the marketing repo and then add to it, and it's almost like a persistent person there or whatever.  So that's what I see, but these are just, you know, inklings of ideas, and I'd love to get feedback from everyone on this.

27:50 - Jonathan Miller (miller.d.jonathan@gmail.com)
  I mean, I basically have my own private version of that, like I've created like my marketer growth person that Alex knows I talk about very often, and even  The comms for this activation we have right here, I've given the conversation I had this morning, the conversations that we had on Friday and Thursday, I gave our community plan, and I gave the spec, and I said, you know, here's what I'm working with, let's come up with some copy to how we should communicate this, and then, like, it's printed out, like, some pretty, like, spot-on stuff, and it has all the context of mother already, and, like, what we've been doing, and where we're going, et cetera.  So, I'm going to host this in a more, like, public repo, or at least a repo that all of us could, um, could access.  Is that, like, a repo, like, is that, like, a GitHub repo kind of thing, or is that somewhere else you want to, you want to live?  Yeah, so should I just start, tell me, really quickly, if you have time, about llms.txt, because I'm, like, looking at this website, llms.txt.org, is this just basically, like, a .txt file?  Is there a format that we're following? Is that all it is?

28:52 - James Young (Collabü§ùLand)
  Yeah, just tell the IDE agent, create a llms.txt file based off of this, and point the URL. And it's a standardized way that the, like, ecosystem, the market is trying to kind of rally around.  And it's by this guy, forget his name, but he's like an AI researcher that is trying to make AI accessible to everyone.  And there's kind of controversy around the lms.tech file, but for now, let's use it. And what I'm thinking is, like, and we're going to, I see that we're out of time, but we'll go over a couple minutes, is that the bot, like, these agents, will have full context of the chat, the community chat.  It will have the marketing plan, it will have access to the code, and it will all combine that. And the orchestrator agent will have access to all these different agents to be able to then be more predictive in nature.  And based off of all of this, be able to, like, formulate, you know, highly specific, highly specialized plans for that community.  And then the community. Admins will add in, you know, their own little sauce here. And I think this is kind of how we, these, you know, in a very practical way, you know, and I'm coming from the context of Collabcellent, but in a very practical way, this is how we get these communities hyped on the agents that we're doing for Mother.

30:21 - Alex Lumley
  James, what you just mentioned is arguably the more, like the context adding. for a community is arguably the more valuable piece of what will end up coming into the orchestrator agents and all the agents.  Like if we actually have a way to pipeline data from communities and marketing people to say, here's the orchestrator agents.  These are just the raw brain dead, nothing in them. And context is coming from all the docs you've written and uploaded here to Gaia.  And now all these orchestrators can actually do stuff that is based on your community. That's really powerful. So what like?  Yeah, because-- In here, with us, is the same thing we could then end up providing to other people.

31:04 - James Young (Collabü§ùLand)
  Yeah, because, you know, as a, and this is just my kind of experience doing CollabMine over five years, admins get burned out all the time.  They can't read and keep up to date with all the messages. But, like, you know, you have summarizing agents, right, that, like, summarize it, a group chat, because you can't even, like, as users, understand the group chat.  But, like, for an admin, just imagine if they don't lose any context from all the different channels in a server, and the kind of insights, and kind of, kind of the mood of the chat server, if things are, like, falling off, or people are getting, you know, I don't know, upset.  It's all the sentiment stuff that you don't have to lose now, and I think this is going to be, like, what the orchestrator agent will also help, kind of, provide.  There'll be a sentiment agent that goes, okay, who has good sentiment? Who has, like, who's working really hard in the Discord or, like, who's just saying stuff just to say stuff, like, you can now have the tool be able to help with that.  And then there's going to be, like, bots that act as users that are going to try to game that.  And, you know, there's one tradeoff and fix will cause other problems. And so now we're going to get into this, you know, new agent-to-agent kind of warp, you know, psyops, if you will.  And so, you know, anyway, this is, I think, you know, as I'm, I'm vibe coding, just random thoughts come through.

32:43 - Alex Lumley
  So, in terms of next steps, it sounds like once we have the, like, the GitHub repo live, we can check it out.  Two, I would also, I would also ask James, if you have any of these chats that you're doing in Claude or wherever, you can actually share them.  We can drop these documents and drop your chats into Slack. That's stuff that we can leverage in context for whatever we end up creating for us as team, but also for the other LLMs.  And then I guess we'll just continue exploring the community plan and how we can take more of the community marketing growth type inputs and put them into LLM.txt to have a shared repository of data.  Yeah. Yeah.

33:31 - James Young (Collabü§ùLand)
  So you can't share the chats. It costs a lot of money. This is how Cursor and Windsor feed their money.  And I've been talking with the main dev at Cursor and they don't have a shared team chat history because then it's like, I don't have to like, you know, tell you stuff.  You can just, you know, when I sleep, I can tell developers halfway around the world, just pick up where I left off.  Yeah. And so they don't have that, but Ian. He was like, that's the number one idea, and I guess it's architecturally or, like, it's significant for their infra.  So what I've done is I have the LLMS.txt, I have a notes folder, and I have a scratch folder.  The notes folder is everything to kind of summarize, and I've put that all in a GitHub repo. Once I start sharing, once the orchestrator agent, all these other agents are kind of more kind of robust enough, I'll open source or at least share with you all, and that will have the notes and the scratch and all the commit history, right?  And I want us to do the same with the marketing stuff. And so everything kind of now moves, like, toward GitHub, because it's not code, but it's content.  So, like, Notion stuff will, and we'll think about this organizationally, how do we do this? just for the guy in it.  Yeah, well, we scrape Notion because Notions are for humans, and then we have maybe some Or some agent that, like, and maybe it's an orchestrator that will then put that into, like, the notes.txt file.  We'll have to come up with some process, just assuming that, like, half the work eventually will be done through agents.  And let's embrace this agentic, synthetic organization.

35:18 - Alex Lumley
  And one more question that I just have, just a general leveraging chats and stuff like that question for you guys.  One thing that I found is that the chat, like, chats are so good at generating text and generating ideas that I found, like, half the time I'm, like, like, I end up just copying and putting into a notion and then making it better and saying, no, here's actually what I wanted.  Are you, are you guys, have you guys found anything else? It sounds like, James, sometimes you end up using, like, unit tests saying, here's where I would like something to end up.  And did it end up there? Double check your work, yes or no, which makes sense. But is there anything else that you guys are kind of doing to make sure that the data that you're feeding back into the, into the chat is, is correct?  right. Okay. The data that you're feeding back into the, what do you mean by that? For example, say I want to make a shopping list, right?  I say, hey, make me a shopping list. And I say, give me three variations and I'll pick which I like best.  And then it gives me three variations and I'm like, oh , I don't like any of these. And it's very hard to kind of edit them and to kind of do it in Canvas.  So what I'll end up doing is like copying, putting in Notion, and then make them prove and say, hey, here's what I like better, here's what I made the changes, and then kind of iterating through it that way.  Have you found anything else that works well in terms of interacting with? Because that's me is one of the biggest friction points that I'm having.  That's where alpha proof comes in, right?

36:37 - James Young (Collabü§ùLand)
  If your interaction, and you save those interactions, and you save that delta, then it learns. And this is why the context is important.  And then it builds up a memory of previous what you liked and what you didn't like. This is a faster way to fine tune the data.  This is the point of alpha proof. It reminds me of like, in the in the States, you had these  The big thing about Seinfeld was it was individual sitcoms, but they had run longer themes and callbacks to other shows.  What we're doing here is we are in the context of just a sitcom of like, okay, you're done. And then like you have a new agent and do something else.  It can't learn from your previous interactions. This is why, you know, with OpenAI, they want to lock you in vendor-wise with memory.  Yep. So like this is where and how we have a process of being able to like put breadcrumbs of memory along the way so future agents can like leverage that and it gets more fine-tuned over time.  That's, that's the next version of environmental AI, experiential AI, that's where that's going and deep seek is like leading that with anthropic and actually that's much better so you can have a very dumb model, you don't have to pre-train it and you don't have to give it a lot of rag, you just go, you deploy it.  And you interact, the more you interact with it, the faster it learns. Yeah. It's creating better experiments for this item to learn.

38:08 - Alex Lumley
  And if you can create a better experiment, the better structure of the experiment, you have a better feedback loop.

38:13 - James Young (Collabü§ùLand)
  And then it can call back to other things that you know, like, say, I didn't like that. So it's not going to try to mention that again.  And these context windows for these LLMs are getting really huge. So you don't have to worry about chunking. That makes sense.  didn't, Coach Jay. So that's what I'm trying to, can we create a process for that, that, like, can take that into account from marketing, from coding, and in the context of a community, then give them what they want and maybe even point them in a direction because the admin doesn't know what the coder is doing or the marketer is doing.  So this is why you have that agent can call back to the other reference points and learn and then better suggest in the future.  So that, like, you said... These three shopping, you don't like any of those, right? Then it learns over time you don't like eggs or you don't like these kind of foods or you're allergic or whatever.  And then it's never going to suggest that. And it's going to be able to fine tune things better. Or maybe then later recommend some type of, I don't know, some novel experimental drug that now you can have eggs.  you tried it? Like there's all these new innovations that get unlocked that we lose context on all the time.

39:26 - Alex Lumley
  Yeah, it's because like, even now, even now ChatGPT has like memories, it has like memories throughout everything, which I've noticed before only with 4.0, 4.0 couldn't do that and now it's gotten much better, but it's very difficult to like name variables in ChatGPT and say, this is, this is what I want tables.  This is what I want stuff in Markdown. This is like, here's the, here's the routine that I have or whatever, right?  It's very difficult to like name variables and for it to remember it. So I think that's kind of like, that's what we would like to get to.  And also say, here's where the.

40:03 - James Young (Collabü§ùLand)
  It's how humans communicate, right? The tighter the community, the more you have these phrases that meet something to those communities.  And when you're outside of the community, you're like, what the ? I don't understand that. But everyone else that's core to the community go, oh, I know what he's talking about.  They have this shared, yeah, like your own colloquialisms, your own catchphrases, right? Like, you know, people coming into crypto, what's HODL?  What's LFG? What is, you know, Wagme? Like, what is all this stuff, right? But over time, you can shorthand, if the AI agent has better context, you can say, tablize this.  I want this tablized. Like, you don't have to re-explain, kind of, this is exactly how I want it. not, it can learn from your specific context.  And you can shorthand better that way in the future. like that. That makes sense, right? Yeah. So that, I think, is kind of where, like, now, when I was reading the papers, a lot of the research on AI is going to.  Like, you don't need GPUs. You can run these models on your phone. And it's just that AI is going to have better and better kind of context over a period of time instead of isolated events that I have to re-explain what is a Collablan account kit.  What is, you know, what I'm trying to do with onboarding? All of that. I can shorthand more and more.  And it can anticipate.

41:36 - Alex Lumley
  This is why I'm so bullish on this company, TinyCloud. My buddy Sam used to, like, he actually did some work at OpenAI, like, four years ago.  And they're building TinyCloud, which is a personalized cloud. My belief is that over time, as opposed to everything being tied to a company, it'll end up being tied to an individual.  And then the individual can report around and share things. there's of on online..chlag I think‚Ä¶ think ‚Ä¶ ‚Ä¶ ‚Ä¶  You should really listen to this podcast.

42:02 - James Young (Collabü§ùLand)
  It was very illuminating. Let me find it real quick, and then we can end. Sorry. Oh, this is helpful.  So this is the podcast. Take a look. It's Don from Nevermind's podcast, and they start talking about this and how like centralized AI versus decentralized AI, you're not going to have these huge models.  And what they're working, there's a company called Jensen that's working on a messaging protocol that like takes the diverse models, which then become diverse agents to then be able to give you better diversity so that you're not like preaching to the choir either, because you need some, some, some variability there else.  Like you, you get very, you get blinded, right? So there's a balance there as well. That's awesome. So it's super interesting.  All right.

42:56 - Alex Lumley
  I appreciate it, James. Thanks for the, thanks for the knowledge. Sounds like you had a great week. Yeah, you know, I'm nerding out, so.

43:04 - James Young (Collabü§ùLand)
  I love it, man.

43:05 - Alex Lumley
  Oh, and the last thing I'll say is I would actually say that vibe coding is not actually vibe coding.  It's just flow. Like if you research like McKaylee or whatever, when he talks about getting into flow, it's the same thing.  And you look at experts, like what artists do when they get into flow is they have structures they create that allow them and they have chunking for themselves that allow them to get into flow.  And that's what like grandmasters do, and that's what everyone does. So it's just getting into flow the same as we always have.  It's just now we have structures and can get into flow in different ways than we could before.

43:37 - James Young (Collabü§ùLand)
  I would also say and argue that getting into flow means that you have to boot up context. Yep. And then when you have that framework and that context, you can go.  And this is where I'm saying, lms.txt with the notes folder, you can get into context faster so that like you can, you know, get into flow, get into vibe coding.  Because in that coding. It's super simple, and you get people into flow, and they're like, they have the context, they know what, and they have it all booed up.  This is why before, like, when I was coding, I needed an absolute silence, because if I lost context, it's on my head, I'm like, , I'd get out of flow.  Now I have to boot up that context all over again, because my kids were bothering me, or like something happened, or whatever, right?  And so that's why when people get into flow, they can't be distracted, because they have all this context in their head.  So getting into the flow really is being able to get into context, so that you can do that middle part.  You're spot on.

44:38 - Alex Lumley
  You're spot on. Well, James, I appreciate it. This is enlightening. Good stuff, man. Cheers. Welcome to my Tide Talk.

44:46 - James Young (Collabü§ùLand)
  Thanks. A lot of people watching Tide Talk. See you guys. James, can you sit for one minute? Yeah, yeah.  What's up? Yeah.

44:54 - Razvan Matei Popescu
  Yeah, you're spot on about flow, because, like, when I create, I'm also a part, I'm artist, so when I...  What's And get into that flow, it's exactly what you described. I never thought about that, by the way, but that's not why I asked to stay with me.  I wanted to ask, like, because, like, from the grant side, we can only apply to base, like Coach said, so the question is, like, how hard or what's...  Is there a possibility to move to other chains as well? Would that be hard for us to implement? Like, I don't know.  I've never done smart contracts or stuff like that, personally, so I just don't know.

45:43 - James Young (Collabü§ùLand)
  So when you do a smart contract, it's where you deploy the contract. And deploying a contract, if none of the feature or functionality from one chain to another chain, it's literally five minutes.  But different chains, may have different... Now these L2s are trying to differentiate themselves. So it really depends on like if Base has like wow.xyz and has all this ecosystem that your contract is depending on that doesn't exist in another chain.  Then you have to, depending on what that delta or that difference is, then you have to readjust. So the ecosystems of each chain are different.  And if you're deploying your smart contract and you're relying on other systems in that chain and you lose that going to a new chain, then it's difficult.  It's hard to know. But if you're just saying I have this functionality and then I want to go to a new chain, then it's like it's easy.  It's like five minutes and maybe there'll be an agent. Let's say it's an agent that knows all the ecosystem on base and it knows all the ecosystem on Arbitrum.  It can suggest to you how if. Your contract is depending on other things in one ecosystem, how to translate that into another ecosystem.  So there's a way, and it really depends case by case, but to answer your very specific question, if you have isolated features and functionality and you want to go from chain A to chain B, it's just deploying that, assuming that both chains actually have the same EVM.

47:27 - Razvan Matei Popescu
  I assume, like, for Arbitrum Optimism, like, from base to Optimism, it should be really easy, right?

47:33 - James Young (Collabü§ùLand)
  Yeah. like, it's the super chain. Yeah.

47:35 - Razvan Matei Popescu
  So for Arbitrum, it may be a little different. So just to kind of explore the ground space, we kind of would also require, like, transactions, stuff like that, apply an Arbitrum, for example.  Like, there is a grand program going on, which is Dowlet. The... Yeah. The act of... ... Thank I can talk with the managers, but I kind of assume what the answer is.  like, the first question will be, are you deploying on Orbitrum? So we'll say we're not. We can.

48:16 - James Young (Collabü§ùLand)
  We can. All of what I'm doing at a high level is to make all of the interactions in Discord, every single interaction in Discord, the north star, is to make every interaction in Discord and Telegram on X be on-chain.  Every single thing being an on-chain transaction. That can be verified. Maybe not every chat message. Every interaction that requires verification or, like, in the quiz, if you answer right or wrong, all the right and wrong answers will be logged on-chain.  All those interactions are logged on-chain. And the way that it's built out, the way that it's built out right now, it's chain agnostic.  So it's just a matter of deploying and having those agents, like I was saying at the beginning, I have a contract agent, just deploy this on Arbitrum now.  And it's like minutes of work. The second thing is like the, so thanks for the answer.

49:15 - Razvan Matei Popescu
  Like I kind of got it. So it would not be that hard for Optimism, maybe a little harder for Arbitrum.  But the second question would be like, these program managers, so for example, in Optimism, I showed you what they're looking for, like, they're just looking for a couple of transactions and on-chain activity, but in Arbitrum, like, they're kind of looking for, like, you know, there's this grant, you know, about grant farmers, stuff like that.  So they're always, the program managers are like inquiring, why are you like deploying an Arbitrum? What's the thing? So can we, can we somehow create products that are kind of differentiated to chain by chain?  can we, can we, can we. Is that possible? So, for example, let's say we can orchestrate... I haven't dug deeply into how the orchestrator works, but is it possible to coordinate, for example, let's say we can coordinate AI agents on Arbitrum and other end-on-base and just to kind of be well-positioned there?

50:30 - James Young (Collabü§ùLand)
  So this is what I would suggest, and this is actually more like grant strategy, knowing that there are grant farmers out there, right?  So let's say we have... I'm going to just give an off-the-top-of-my-head example. You have, and I'll be specific, you have a DeFi agent, and it will do stuff like add liquidity and all this stuff on Uniswap, right?  Now, we can take that base function... And then when we apply to a grant on Arbitrum, we can say, well, what we're going to tweak this DeFi agent, because maybe there's a special feature on Camelot, which is on Arbitrum, that's not on base, for example, and this special tweak allows for, I don't know, better staking, swapping, or whatever it is.  So as you're writing the grant, you have to understand the nuances of that ecosystem, and what specific leverage the agent can have on Arbitrum, so that you can't just leave Arbitrum, because now that agent is stuck with the special functionality of that ecosystem.  And then talk about how the grant will not only unlock, I don't know, whatever that feature is, but why does it unlock it specifically, why Arbitrum?  Because... Because... This Camelot Dex has these added features that don't exist on Uniswap, but you don't have to start from scratch when you're moving from Uniswap agent to the Camelot agent.  You just have to add this extra feature or two, and that is, I think, will be appealing for the grant tours to go, oh, they know about the Arbitrum ecosystem and how it's differentiated.  This agent will highlight that differentiation, and I think that is how you beat out the, like, grant farmers, because you say, I have a base agent, so I have half the work already done.  I'm going to take it and I'm going to put it on Arbitrum and add this specialized feature that only is in the Arbitrum ecosystem.  So, you're not competing with people creating grants from scratch, and you're tying your agent and the grant to specific.  you.

53:05 - Razvan Matei Popescu
  Got it. Like, that's kind of the idea. The thing is, like, the grants are pretty, the program managers are pretty picky.  So in Orbitrum, I know them. I have some reputation there, which counts, but like, they will not give us a grant just based on that, like.

53:26 - James Young (Collabü§ùLand)
  So let's talk about that. Because you have insight from the grant managers. And what can we do that will meet their needs?  They're like the customer. Yeah, exactly.

53:40 - Razvan Matei Popescu
  So we should be very, first thing, we should be very descriptive, precise, and accurate on what we're trying to do.  Like, with the amount, with the way we describe the product, with every single thingy, because like, they like to nitpick.  And especially... And what they love to see is using Arbitrum tech, so styles and stuff like that. So that makes it more approvable, let's say, leveraging Arbitrum native tech and stuff.  So technically, I don't know how that could be done, but that's what I know. So they, because like, you know, every program, every program manager has people in WebTree rarely understand this.  Like every program manager has an incentive to kind of give out the funds. So they, they never think about that, but like, that's, that's, that's what sucks.  So they, they, it's like, it's cool, but at the end of the day, it's still like pseudo popularity contest.  So the, the more, oh yeah, absolutely you have, like the more bam, bam, bam, bam, get, it's.

54:55 - James Young (Collabü§ùLand)
  So what I'm hearing from you is that when applying for a grant, if you know the. Program managers. Applying for the grant is really how do you make the program managers look good?  That's incentive, really. How do you make them, like, you know, want to say, we need to get this grant because their incentive is to look good and to go up their hierarchy or whatever, their promotion path or whatever.  It's like when you sell to enterprises, big corporations, you don't sell a product, you sell a relationship, and this is, and you're listening to that person in the enterprise and saying what their needs are and what's going to make them look good, then they'll become your champion.  So you want to make it easy for them to promote your grant, and that's why it's like you have to have, and you already have, and you have this insight of these relationships and what their incentive, hidden incentives are.

55:50 - Razvan Matei Popescu
  Yeah, I have to say, like, it's, it's still like, these guys are tough. So for example, from quest book, the max we can get, it's 50k, but like the, the.  Because everything is open, everybody can see all the comments, all the stuff, so it's that, plus it's looking good, plus the actual work, so it's kind of both right now.  Because Questbook is the only program, like last year we had three, now it's, all eyes are on it, so it's, it's kind of extra pressure on their behalf, so from the program at IGPU.

56:37 - James Young (Collabü§ùLand)
  Yeah, this is where I lean on you to get your insight in terms of the politics, because whenever you deal with humans and money, you're gonna have politics.  So, like, what, what, what are the, like, political landmines that we have to, like, fight and get through? And that's why it's like, it's like being a politician, almost.  True.

57:00 - Razvan Matei Popescu
  True, true. Well, yeah, it sucks because RBGM also had an AI grant program. I have to ask about that.  It was only focused on AI, but it's winded down. So I will, I will share some examples with you.  Like I'll get a DMU, like, for example, how a grant got accepted looks like. yeah, it's, it's really, uh, they're many DeFi, but I would say what we're trying to do is a protocol, right?

57:33 - James Young (Collabü§ùLand)
  Like this is a, what we're trying to do is create a registry. That's curated by a DAO that of credible, verifiable agents.  And because we're doing that, we may have to build our own protocol, but the AI landscape is changing so quickly.  There may be protocols that we don't have to build from scratch. We can leverage, like MCP and A to A.  So that's the difference there. But our end goal, what we're trying to do at the highest level is create a registry of credible agents, of verifiable agents, because there's going to be millions of agents, but a lot of them are going to suck.  A lot of them are going to scam you. So how do you know what agent to trust? That's why you need a blockchain.  Who will curate them?

58:27 - Razvan Matei Popescu
  Will it be people, other agents, people plus other agents? It will be the mother DAO.

58:34 - James Young (Collabü§ùLand)
  And there will be people in the mother DAO, but as the DAO gets more history and is able to then really be automated, these people will have their personal agents vote for them in the future.  Okay.

58:58 - Razvan Matei Popescu
  Yeah. go.

58:59 - James Young (Collabü§ùLand)
  Boom. Boom. That's Boom. Boom. Boom. Boom. Thank And I think the questions that you ask is, they're very big questions.  I don't know if they'll be solved in one meeting. It's a dialogue, a conversation that we need to have.  And things will change. Program managers will come out, new ones will come in, will change the environment. And grants will come and go and things like that.  So I think that maybe we have, you know, like a grants work stream, which you're leading to help with the conversation of how to best land these grants.  And we're just beginning that right now. And these initial questions are going to set the context for us to then learn and grow.  And I would also recommend that we can use maybe an LLM and have a history so that the grant requester agent becomes smart and we can start getting more context there so that you don't have to repeat your same thing over and over again to other people.  They'll be able have that history in that context, and what they're missing, they'll just ask the agent questions, but that will unfold over time.  I should start building that.

1:00:11 - Razvan Matei Popescu
  I've been also looking into how to, since I started DAO, I've been kind of detached from technical stuff, but it's good to rewind.  So I won't keep you anymore, like, I'm gonna look, cause like, I'm gonna try to apply for the base one, and I'll probably ask you, coach, for some, like, one-pagers and stuff, like, what's the most relevant information we have at the moment.  And yeah, see what base says, and by the way, have you spoken with Joe lately? Like, is he coming back tomorrow?

1:00:51 - James Young (Collabü§ùLand)
  I haven't spoken to Joe in weeks, maybe months, like two months.

1:00:56 - Razvan Matei Popescu
  Oh. Interesting.

1:00:59 - James Young (Collabü§ùLand)
  Just keep going.

1:01:00 - Razvan Matei Popescu
  He told me he's taking a break from startup life, but like, I don't know.

1:01:04 - James Young (Collabü§ùLand)
  Yeah, I think he's focusing on his health right now.

1:01:13 - Razvan Matei Popescu
  Yeah. I hope he's good.

1:01:15 - James Young (Collabü§ùLand)
  Yeah, me too. Me too. I'm just giving space because he has to, you know, deal with life and stuff.  So I haven't reached out to him and he hasn't reached out to me. Okay, cause like, do you know Serana?

1:01:28 - Razvan Matei Popescu
  Like, she's keeping track of her hours, I think. Uh, I know Serana.

1:01:34 - James Young (Collabü§ùLand)
  I haven't never spoken directly with But I think, from my understanding, on the org side, like the HR side, with tracking hours and things like that, Matt is taking over for that.  Since when, do you know? Maybe, like, a month back? Back, three weeks back, something like that. But do people know that?  Uh. Um, I, I might be wrong, I don't know, this is who I'm just trying to get a hold of Matt to kind of get the org together and get some questions answered, because I have some questions for Matt as well, like with this whole MCP thing that Gaia put out, and I don't have full visibility.  I would ask Matt directly in Slack or in the Romacuria channel. Okay, because Sorana has been asking me and probably everybody every week, like, how many hours they put in, so.  Yeah, the communication I have with Sorana has been, do I approve of these engineering hours, and that's it, because I was just doing the engineering side.  And since we don't have any activists, I'm the one that's engineering stuff now, I'm developing the code. I haven't talked to Sorana in, like, two weeks about approving anyone's hours, because I've just been focused on the engineering side.

1:06:03 - Razvan Matei Popescu
  But this is a good question. I highly recommend just in the Slack, just asking Matt directly, or not DMing, but just asking the group chat so that, because we, everyone needs to know this info, not just you.  So I'm not exactly sure what's happening. Yeah. Do you think we lost Matt? I hope not. I hope not.  I don't think so. I know Matt's just really busy. Yeah. Well, okay. I'll ask him the efficiency truth, I guess.  Yeah. That would be great. That would be great. And it can help. I don't know what I can do.  I've just been on the engineering side. But it's like, now I feel like I'm leading most of this. So I need answers for Matt, too.  So if you put in the group chat, then I can understand the conversation. And I can have context, too.  Yeah, sure, sure. How would you recommend me asking this? Like, just like, hey, Matt, who's counting our hours? Who's our hours right now?  Yeah, Okay. You dude what instructions took to prove it here. I'm a skate. Uh, sorry. it later better my Now, closing, playing to Yeah, so getting inside?  You're Thank you very much. Thank you very much. What are you doing? What are you you doing? Why? Why?  Why? It's clean. Clean? No, I'm going from that one. I'm going to to Germany. Why again? That's fine. Okay.  Mariana? Anna! Zbignian. A√æŸáÿß Bj√°. Hann s√¶t √æ√∫ hung Morgan √≠r —Å–∞–º. √Ü? J√°. var √æv√≠ fasta, √æannig a√∞ brygg.  √öst. √Åka n√°kv√¶m. √ûa√∞ √° einnig meginn. N√°, ok. N√∫st barni√∞. N√∫st √° fattu √æra√∞u They ate it, they They ate their to the noms.  Did remember? The comunism. The memorization. Yes, ate it. at a bottle of milk. they came with milk. had the milk they came with milk.  I don't like a zombie. Whiskey. Yeah. Yeah. I'll see you next I'll see next time. I'll see next time.  I'll see you next time. I'm going to go to the next video. you. . . . . . .  . . . .
