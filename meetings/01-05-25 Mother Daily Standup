Mother Daily Standup - May 01
VIEW RECORDING - 35 mins (No highlights): https://fathom.video/share/AqQ6GVWs1Y9J_5FvKBfT5ogXPtzfthsx

---

0:00 - James Young (Collabü§ùLand)
  All right. So what I've done is I committed an open source, my latest, what I'm doing with the QuizBot.  And I've kind of gone full circle. And it's really been interesting. So you can look at the, there's a, created my structure just to let everyone know.  I won't go into the details of what I did with the QuizBot, but what's relevant here is I created a context folder.  It has the date and kind of a, in the file name, a summary of what it does or what I've been doing kind of overall.  And then I have a LLMS.txt file that instructs the agent ID to like, you know, give complete context of everything that I've been doing.  So I have organized and I've been playing around with this. So I finally feel comfortable. And open source it where there's like in the context folder, if you see the date and like a string, because there might be a couple of context for the same day, it just gives a human an easy to read kind of brief of what's happening.  And then there's a corresponding llm.txt where I have like, I prepend like a domain, kind of what the kind of overall context is.  But the llm.txt file is very verbose. And if you have the inkling or the curiosity, you can see how I've gone full circle with the ask command.  And part of the reason why I open source that is I learned yesterday that Toby, now full time at Gaia, is also working on some type of orchestrator kind of agent.  So instead of having to meet with Toby, I'm just going to keep. of just right, I'm have have find I can  This, like, this slash ask orchestration open source as we build in public so he can leverage it or not.  So it just saves a lot of coordination time. And I also wanted to bring this up here because this is the format I think we'll move to it.  Whatever you guys want to do for, like, the meetings and the transcripts and things like that, feel free to have your own structure.  But this is a structure from a code perspective for the IDE agent that is working. And maybe we'll iterate through that.  So I just want to let you know that. I talked to Kushagra yesterday. He said that he's back in Dubai, so he couldn't make it.  This time is too late for him. And I don't see Toby in this meeting either. And what Kushagra said that he would do, I don't know what the, I think Toby's in Nigeria.  I don't know what the time zone difference is, but I think it's closer to Dubai time than it is mountain time.  And so they're coordinating separately. So instead of having to all coordinate. This meeting, they're coordinating. I hope I didn't actually tell Kushagra or Toby to record it, to loop back into the larger context here, but we'll see.  And, yeah, that's kind of the update for now. I'm feeling really good about it, you know. It's really interesting, this whole kind of new shift organizationally that we're moving to.  It's making a lot of sense to me when I ask myself questions as I'm coding and doing things, and I think this is how we coordinate.  So I'll just give a one-minute kind of overview of my take. Like, what Transformers did in 2017, it really changed the whole AI industry.  Ilya was a co-writer, author of that white paper, and the white paper was called Attention is all you need, and it's really interesting how that now, for me, makes sense in that, yeah, you need attention.  Without attention, you don't have anything, but that's like the surface level. From attention, then it allows you to have context, and the first pre-training LLMs script the whole internet as a context of the entire world.  But, like, it's hard because, like, it's just too much space, and it's too much context, and it's way too broad, and so refinement learning, what it does is it takes that pre-training data, and it, like, then tries to narrow that attention space of the whole internet and focus it on, like, if you think about it in vector space, which is just like in 3D, a certain place.  And then people are trying to use a pre-training focused on... A certain space to then take action and have these agents learn, but I think that the experiential AI, I've been researching a little bit more, actually, what you need is just the model to understand essentially English, know how to call and response, right?  We all speak the same language, but you don't need that refinement learning. You don't need the whole context space.  What you need now is that interaction to provide that context. That is kind of the reinforcement learning, this experiential AI that we're building out right now to give specific context in terms of what we're exactly doing.  Each community, each project, each online organization is going to have their own separate context. And so I think this is a general wider pattern that is kind of a little meta as we move forward in this, that like we can actually set kind of the new rules, if you will, when it comes to how people organize online.  much. Thank How to, you know, have this hybrid synthetic human relationship because we are all mediated right now in this meeting through technology.  Everything is recorded. All the interactions are able to be read programmatically. And I think this is kind of this really interesting or fascinating aspect of coordination.  So it goes from attention to context to coordination. And I think that's kind of how I am thinking about it at a high level here, just to give a broader view in terms of why I want us to, like, do all this kind of extra work.  It may seem a bit frivolous and they're probably going to be mistakes that we make along the way or assumptions that we will see if they're true or not.  Just like with the agent starter kit, you know, we thought agent devs are just kind of like integrating all this, but we pivoted to this fast track program.  I think we're evolving and would love to keep these meetings at a high level where it comes to, like, not only.  Not only talking about the work that we need to do to move the organization forward, but this kind of, in a way, this meta understanding of like how what we're doing in real time is shaping the process of remote only or online first hybrid organizations.  So I'll jump off my soapbox there, but that's kind of how I think about this and what we're doing, and it's super fascinating.  And I'm assuming as I'm coding, as I'm Vive coding, I'm assuming this context. And this is where I think it's going to get really interesting.  And I think this is where we get kind of the beginnings of being able to leverage. So we're doing this groundwork now.  We'll be able to leverage it, and this is how we unleash the real power of AI, think. And not mapping, like, old processes to new technology.  able future. We'll continue of mm if Thank That's the trap that I think a lot of people do. Again, you know, when you look at the car engine, it's measured in horsepower because that's all we had prior to vehicles is horses, and that's the context that got driven over, but no one understands what a horsepower is or what that means.  There's a measurable definition now of what horsepower is. It's an old term, but in the same way, I think that we're going to map our processes that we know, whether it's Scrum, Agile, Voice of the Consumer, we're going to map those into new AI or agentic enhanced processes.  So, we try to be skeuomorphic because that's the context that we all know, but as we move into these new contexts, let's just be aware of these new processes, and we think in analogies, and that's how we move forward contextually.  know, something is like something else, and that's how we shortcut. And be able to get everyone up to speed.  It's not that we think logically, step by step. And so I just want to have awareness, I guess, of that as we move forward.  And we're developing new processes as we're kind of building the plane. We are creating the new tools to create a better plane while creating the plane at the same time.  So I just want to acknowledge that and make that kind of overt instead of an assumption. So with that, you can see the repo where I'm at when it comes to all that I've been building out.  I've given the AI the full context of this full agent, multi-agent space. It uses MCP, it uses A to A, and it then, but it's like, it got very complex, super complex with MCP, A to A, all these interfaces, all these agents.  So I circled back, and I want to just focus on delivery, so the IDE agent knows about MCP-80A, but it knows that it's going to be what I call a monolith agent for now, so that we can just get to production.  But it has that context knowing that I want to start with this monolith and then subdivide these out into multiple agents step by step.  And so that's kind of the whole context. The repo is in the Slack, but I think I might have it in my clipboard here.  So I also put it in Google Chat as well. But it's in the all-mother Slack, so everyone can reference it outside of this call as well.  So that's my status update, and I think about half of the meeting there. So I'll pause and get feedback, or if there's anything else agenda-wise to set up for tomorrow's what we should call, maybe this helps.  I had something to show or just kind of this meta learning and process that we're going through. don't know if that's useful in the what we should call or not.
  ACTION ITEM: Prep demo of GitHub repo & Discord bot for tomorrow's meeting. Include screen sharing of test Discord server. - WATCH: https://fathom.video/share/AqQ6GVWs1Y9J_5FvKBfT5ogXPtzfthsx?timestamp=668.9999  So I just want to give everyone kind of that, my two cents here, but I'll stop there.

11:19 - Alex Lumley
  That's awesome, James. Just one thing for in the future, it'd be great if when you're kind of talking to this, if you actually just bring up the GitHub and just walk us through kind of where things are, how it is.  I think that would also be for the context of like the context sharing that we can put into GitHub.

11:48 - James Young (Collabü§ùLand)
  You're muted, James. Sorry. So I'm screen sharing. What I'm showing you in the screen share is the brand for that quiz agent that has all that content.  Context in the LLM and in the context folder of what's happening that you can just point in a source.  you can just point your chat GPT to and ask it questions. And the spread is specifically on like the slash ask with the MCP, the A to A, the multi-agent, but then starting with the monolith.  There is the main branch, which is just a template. So if you go just to the main branch, you can actually, in the README, follow the prompts.  So I assume that devs are using an HNIDE, and you should be able to get up to speed and create and like have your own bot.  Because there's technical things that you need. You need like a Discord app token, and you need an ng-rock funnel, you need to have your own Discord server, and you have to do all of that.  So that context, when creating a bot template, instead of it being in a README, I put it into an LLMS.txt, and you in the README.  And you can just prompt your way to getting this all done. So I'm doing that for Discord, and I'm doing that for X.  And the idea is that these agents in the multi-agent world will be able to do its specific tasks. So whatever we're building on Discord will then be able to reflect on X.  X has a different formatting. It's a card. It's not Discord. But then the X card agent will be able to format the poll, the quiz, the quest.  In the context of an X card. So the poll, the quest, the quiz agent doesn't need to know about the platform that it's launching on.  And that's what, like, the Discord formatter agent is going to be for Discord, and the X card formatter agent will be on X.  So just building that out. So that's pretty much all I have. If you see here, there's this context folder.  Am I in the right window? All So Yeah, so, one sec, then you can see all of this, you know, there's a setup LLM, there's an orchestration LLM, there's a monolith LLM, and what I have in the root directory is a context LLM that tells the IDE agent, if you're in the branch, to read the LLMs.txt and then look into all the sub LLMs.txt and the context the LLMs to be able to get full context.  So the IDE agent will have full context of everything that's happening, kind of step of the way, and as I have more commits, then you can tell the IDE agent to read the commits and all the branches along the way.  So it gains that experience. So maybe I'm overfitting a lot of this context and the experience AI, but this is the investigation to do.  And we'll figure out and we'll level level At terms of like what to put in that context folder, how much, how little, and it'll get better over time, I think, as we commit so that we don't lose this like organizational history, right?  So it's like, you know, big corporations, they have people that churn come in and out. But here what we're trying to do is have the AI be the organizational historian and tell all the stories along the way from one to now.

15:31 - Alex Lumley
  It makes sense. This is the new like database structuring that like everyone takes so much time doing. It's like how to set up your context pipeline is the new, like a new part of the architecture that has to like get figured out for teams.  So it makes sense that we're experimenting that way. So in terms of tomorrow, I think it'd be great if you showcase this, share your screen.  We can, we can show it all, have you walk through it. I assume this is, I assume. I assume this template is, like, it's not actually live yet, right?  Like, is there a Discord bot in Mother right now, or is it just this is already set up? This is on Collabland.

16:14 - Jonathan Miller (miller.d.jonathan@gmail.com)
  Yeah, so I have my own test server that I'm testing this on right now.

16:19 - James Young (Collabü§ùLand)
  So what I'm assuming, there isn't, like, one production place where this is released because it's still in development. But anyone can take this code, set up their own Discord server, and replicate this.  It's all local development at this time. It's not, we're not at the staging or production.

16:35 - Alex Lumley
  Yeah, well, what I meant is, like, if you, like, I have access to your Discord server. If you can even just show your Discord server tomorrow and show people, hey, here's how it works a little bit.  So you can kind of see it end to end. Sure. That'd be great. And then for tomorrow, Tosh, did you want to show the data pipeline stuff or anything you wanted to highlight there?
  ACTION ITEM: Prep showcase of AI for project mgmt. Highlight challenges w/ remote work & context sharing. Explain meta-level approach. - WATCH: https://fathom.video/share/AqQ6GVWs1Y9J_5FvKBfT5ogXPtzfthsx?timestamp=1012.9999  So I was trying it out today.

17:03 - Natascha Tiotuico
  was already talking to James that my chat was fully hallucinating, saying that Ben was in the meeting. And I was like, are you sure it was Ben?  I think James said that. And they were like, oh, yeah, you're right. Sorry. Let me clarify. Ben from Collabcellent was not a guest in the meeting.  I was wrong. And I was like, okay. So it might be a bit confusing for me to showcase that.  But I can like talk a little bit about our challenge with remote working that we're going so fast that, you know, even if we just miss one meeting, that we noticed we're kind of out of context.  So we came up to use this also for our project management. And and. I can show that a little bit, I probably can't, I'll see how much I can prompt, because I'm just like getting upset at my GPT for telling me so many lies, like I was like, who's Toby from the meeting, and they were like, oh, he was a guy, he's working on the quiz bot, and like, no, he wasn't working on the quiz bot, so it wasn't, I guess we don't have enough context, that it's really working well, so I think just talking from a meta level on how we're going forward, and how we're going to do this in the future would be good.  It might also be helpful, so two things, one, because I know, Tasha, you were saying, like, you're still getting up to speed on a bunch of this AI stuff.

18:47 - Alex Lumley
  It might also be helpful to review the OpenAI, like, playground, and their prompt engineering stuff, and so you see how to better structure the prompts, because my, what I'm imagining is a couple things.  One is, you probably have be like, Hey, by the way, don't make up  if you don't know it. And then two, also, in the context, we might have to add another file that is like, here's the people who are typically in the meetings, here's some of the additional things, and so you might want to test out some of having, putting some of those things in, even like the mother white paper or other things like that, and see what kind of gets pulled out from there.  Or additionally, Tosh, maybe the other thing is, at least for some of our previous meetings for the past week, I know I get like fellow summaries.
  ACTION ITEM: Send Natascha recent meeting summaries & transcripts from Fathom for AI training. - WATCH: https://fathom.video/share/AqQ6GVWs1Y9J_5FvKBfT5ogXPtzfthsx?timestamp=1165.9999  Yes. Maybe I can send you some of the summaries that we have, like the summary and the transcript, and that way you can learn from both.  Yeah, I think Fathom from Jonathan is pretty good.

19:45 - Natascha Tiotuico
  So if we, if we maybe add a few of those good meetings where we've talked about, like how to prioritize which agent we're using, et cetera, and it might be nice.  And I'll I mean, even tomorrow, if I say, yeah, it's still hallucinating, but we're working towards that. And then James comes and shows his nice structured way in GitHub, how it worked, then at least we we can show that we're innovating the way we work together as well.  Also assuming that more people will join as soon as we're like successful and they need to be onboarded and get up to speed.  What because when like five, six people like us work very closely together, it's hard for outsiders to join the product project at some point.
  ACTION ITEM: Develop 10 test questions for AI. Use to evaluate & improve context understanding. - WATCH: https://fathom.video/share/AqQ6GVWs1Y9J_5FvKBfT5ogXPtzfthsx?timestamp=1235.9999

20:46 - Alex Lumley
  The other thing I'd recommend Tasha is is almost like some some of the test of development, pull out like 10 questions and say, hey, answer these 10 questions and then just check to see if it can answer those correctly.  Yeah.

20:58 - Natascha Tiotuico
  Okay. Okay. Thank Is there anything else that you wanted to showcase tomorrow?

21:05 - James Young (Collabü§ùLand)
  I defer to Coach J or Zero8 if you have anything else, but just to kind of rip off of what you were just talking about, this is part of the experiential AI.  This is the refinement learning, so it doesn't hallucinate. And then it takes that previous context to then be able to refine and understand better.  So I expect that we didn't give the AI, it's just like another person. Like we didn't give it much context.  We just threw it into a meeting and go, okay, like figure it out. So there's misunderstanding. So over time, and I think this is part of the context shaping, the requirement learning, is asking you questions and things like that.  And like maybe in the future, this is kind of off a tangent. But if we're onboarding new people into the mother org, maybe we have them spend a day.  Like talking to the AI and answering questions. easier. purchasechantions. Because it shouldn't be, okay, this is what we expect you to understand.  We want that new person in the org to get full context. And so it should ask questions. And then it could also help debug any context it doesn't have.  And then that helps future onboarding individuals as well. So we want to create these recursive processes, these experiential AI, and then it just gets tighter and tighter as more time goes on.  And it's not, like, episodic where each, you know, you're just taking, like, if someone comes in two months from now, they don't have context in terms of how this all started with the starter kit and then, like, with Disruption Joe or, you know, other Xena or other people that are no longer in the project.  It can actually know who these people are, what they contributed, and all of this. This then leads into other offshoots, like a reputation agent, right?  If we wanted to, like, create an algorithm, who's participating the most? It's who's contributing the most, who's adding the most value and all of that to the org.  There's offshoots of this, that this is why having this hybrid AI can open the surface area to things that are problems that are just impossible to be able to coordinate if you didn't have this AI.  And this is why it's not skeuomorphic. We can't just replace our current workflows with AI. We're creating new spaces and new possibilities that didn't exist before.

23:37 - Alex Lumley
  Or said differently, James, people wanted them to exist, or they had the idea like, oh, I wish I could do this.  But because there was a gap in terms of the implementation, like they couldn't get to that, even if people wanted to or thought about it.  So they just had non-consumption and they just couldn't do it. Yeah, that's true.

23:55 - James Young (Collabü§ùLand)
  It's kind of like, you know, in the beginning of the internet, people always thought, oh, this is just... A homepage, and they thought, oh, we'll just put newspapers online.  But they missed this interactivity that led to social media, where now news outlets are actually now not the way to do it.  You don't get breaking news from the New York Times. You get breaking news by this crowdsourcing of information where people on the ground are like saying this, that, and the other thing.  And, you know, and then that gets mediated by the X algorithm or the Facebook feed or whatever. So you're only being able to pay attention.  And this is this kind of like kind of power dynamic that goes back and forth here. And I think that, oh, just one last thing.  I think that if we really want to value aspects of decentralization, we need kind of a impartial referee. And that's what the AI then can become.  And I think AI is critical for decentralization. And else you get just the same constructs of like people organizing.  So there's these, like, soft issues that we're going to address, and so want to just not just hone in on the technical implementation, but also kind of look at it from a higher level, kind of how group dynamics work and how AI changes the nature of group dynamics.  So it's not just one person with a lot of influence, but may not, like, be able to add a lot of value, or just because they're large token holders, the whales sway the boats and things like that.  I think this is how AI can really be used, and I want us to also kind of keep a mind on that as well.  Go ahead, Tash.

25:45 - Natascha Tiotuico
  Yeah, so actually, two days ago, I also watched the EU AI Act. There's going to be, like, some things that companies in Europe have to perform.  usually create a lot of like almost They're like, documenting what they use AI for and stuff like that. So it's also got to be interesting how, like, how these things can be used in, like, normal companies and stuff like that later on.  And, like, of course, like, we're talking in CoUnity and everybody was like, oh, we want a contact agent. We want a contact agent.  So we're having a lot of place to experiment with that, and I'm really looking forward to it. That's awesome.

26:37 - Alex Lumley
  I just dropped this forum post about one thing, a really simple thing that we could use in the Discord agent is the Together Crew functionality to have a summarizer.  I would imagine they could probably expose that endpoint so that we could leverage it in this bot. That's probably for next week.  So the last thing I'll say, just kind of wrapping this up for today is, so this is really early.  This is what I'm talking about here, but Tosh and I have been meeting a couple of days this week in the background about something that I find incredibly important, which is shaping our lean canvas, which is a business model thing, and doing that and understanding the voice of the consumer aspect of this, where the goal is to get something where we can get people to actually start paying us for what James is working on and developing.  Because my hypothesis is, is that what James is developing like today and in the next 10 days and all that will likely be able to add value to teams right away.  So can we actually get other teams to pay us and do that? And so part of that is creating this business model, creating this lean canvas, and then kind of like batting it around, making sure it all works.  And then going and doing some interviews with teams around, hey, community managers, what do you guys currently do today?  And the tool that I use, what's awesome is they had a course yesterday on it. They've actually now incorporated AI into it, where you can get your interview transcripts.  interview transcripts. Put them into their tool, it does sentiment analysis on it, and it unpacks the jobs that it finds for that.  It's super interesting, and it also reduces the amount of work you need to do when you're doing interviews. But the point of all this is that as we're actually building this, we can get people to start paying us sooner.  That's the validation. And then we can start developing for these three to five to ten pilot teams that allow us to go towards the direction that works rather than just doing stuff for the mother AI.  Yeah, I think there's a meta learning here.

28:32 - James Young (Collabü§ùLand)
  And so I think this is all great, good stuff. Because like if there's a voice of consumer or lean canvas agent, then it could actually then integrate with like a poll agent.  And these interviews are just like random polls that are in the community. Right. And there's new ways of interacting.  And this is the surface area that can then now be a lot more automated. If these agents all have shared contacts.  text.

29:03 - Natascha Tiotuico
  And we can create, like, free model where we can say, hey, we can integrate the mother and you pay as you go, like, how much volume, and then at some point we refer packages on how to pay or get control of the payment model.  Yeah, that's right.

29:24 - James Young (Collabü§ùLand)
  What we're seeing at Collabland, real quick, I know that we're one minute over, but maybe we can close out with this, is that, like, these community admins are now becoming the new KOLs.  And so how do they empower them and their influence? And because these KOLs, they like to launch tokens and, you know, hype things up and get that latest alpha, but they don't like to manage a community.  So if all of this comes into where, you know, a KOL can then just automate a lot of things, have a new skill set, where they're not having to read all the comments and keep track of the community and, like, you know, Okay.  People are complaining, all this kind of stuff. If that can be boiled down into some automated process for agents, then I think this can also help with where we're at in the cycle of meme coins, KOLs.  Because at Token 2049, what I've heard is that it used to be a lot of investors, VCs used to come to it.  But now these events are overrun by KOL agencies. Because they are the new kind of investor. So there's like new personas that are being created as well, that old processes can't tap into.  So there may be opportunities there for revenue generation.

30:49 - Natascha Tiotuico
  Very cool.

30:54 - James Young (Collabü§ùLand)
  Okay. I know we're two minutes over, apologies, just super excited. I get geeked out into this. office. Okay. But I think that there's a lot of potential here and let's continue pushing this forward and experiment in real time on the ground and be practical with it.  One last question. I'm going to ask if you have a Tosh because I think she was thinking this.

31:14 - Alex Lumley
  James, do you have any good resources for Tosh that can help her with prompting and chat to T and doing all that?  I recommend it just the like Anthropic has a bunch of good resources. OpenAI has their playground in the prompt engineering.  Is there anything else that you've seen that's that's really good that she can leverage that to then kind of train or do the prompting on this?

31:34 - James Young (Collabü§ùLand)
  You know, I think a lot of this right now is everyone's like learning about AI. And this is why I like these AI companies, they charge money and everyone has like multiple subscriptions.  You have to like play with it. And then for your specific issue, like Tosh was talking about the hallucination, just like Google it or like, you know, look at YouTube and always a certain on  Start following people, and this is, there's no, no one has a set playbook. This is the window of opportunity that we have.  So we have to kind of bang our head against the wall a little bit, and based off of whatever issues you're facing, like try and like Google it, YouTube video it, follow people, and try and understand, because this is how you learn, and this is the competitive advantage.  The, the, the pre-prompt kind of instructions that I've been following are very specific to development, and this is where like I came up with these kind of guardrails, and this is just through my own experience of you spend a lot of time on the design phase, and this is what led me into like this conversation in terms of context sharing, because I was like this is more than development, but on the developers it's like design and get your AI as much context as possible, and then write all your unit tests, so that then it could like  The AI can get into flow because it knows what you want to do, it knows what your expected outcomes are, and those are the constraints.  So how you do that for marketing or community management, the tax and the prompt may be different. But that's the meta kind of pattern that I've learned just specifically, like, as people are banging their heads because, you know, even like four months ago, you know, the AI would be caught in loops, coding-wise, and it would be hard to get out of.  But that is quickly now becoming a thing of the past. Remember, like, the images back in the day where the AI couldn't do the fingers and now it can do fingers well?  It's just as it's learning and getting more information, it, like, it can learn better and faster. And that's why I think, like, this whole experiential AI is kind of the direction of AI and where it's going.  And since we're focused on, like, crypto communities, Mother AI being our initial reference implementation, that, like, we can apply.  . Those learnings and this experiential AI to mother AI first, because then it gets too philosophical, too abstract, and we lose touch.  We get too ahead of the market or we go down a path that's not relevant anymore because things are changing.  So I think focusing on the mother AI discord is the way to be in the arena and take in all the innovation that's continually happening in AI.  Love it. Great job. That's a great way to frame it, James.

34:32 - Alex Lumley
  And the last thing, Tasha, is just make sure you're paying for whatever tool you're actually using. And otherwise, just schedule some time with me and I'm happy to show you some tips and tricks.  Thanks, guys. Thank you. Awesome. Thanks, everyone. Bye. Bye.
